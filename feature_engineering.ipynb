{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def haversine(loc1, loc2):\n",
    "    \n",
    "    loc1_rad = np.deg2rad(np.asarray(loc1))\n",
    "    loc2_rad = np.deg2rad(np.asarray(loc2))\n",
    "\n",
    "    R = 6371  # Earth's radius in km\n",
    "\n",
    "    delta_lat = loc2_rad[0] - loc1_rad[0]\n",
    "    delta_long = loc2_rad[1] - loc1_rad[1]\n",
    "\n",
    "    a = np.sin(delta_lat / 2) ** 2 + np.cos(loc1_rad[0]) \\\n",
    "        * np.cos(loc2_rad[0]) * np.sin(delta_long / 2) ** 2\n",
    "\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    km = R * c\n",
    "\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_grid_latlong_train(lat_up, lat_down, long_up, long_down, cell_size):\n",
    "    \n",
    "    dkx = haversine([lat_up, long_down], [lat_down, long_down]) \n",
    "    dky = haversine([lat_up, long_up], [lat_up, long_down])\n",
    "\n",
    "    Mx = np.ceil(1000 * dkx / (cell_size)) \n",
    "    My = np.ceil(1000 * dky/ (cell_size))\n",
    "\n",
    "    DX = (lat_up - lat_down) / Mx\n",
    "    DY = (long_up - long_down) / My\n",
    "\n",
    "    cell_polygons = []\n",
    "\n",
    "    for i in range(int(Mx)):\n",
    "        for j in range(int(My)):\n",
    "\n",
    "            z2 = lat_down + i * (lat_up - lat_down) / Mx\n",
    "            z1 = z2 + DX\n",
    "            z4 = long_down + j * (long_up - long_down) / My\n",
    "            z3 = z4 + DY\n",
    "        \n",
    "            V1 = np.asarray([z1, z2, z2, z1])\n",
    "            V2 = np.asarray([z3, z3, z4, z4])\n",
    "            \n",
    "            cell_polygons.append([V1.T, V2.T])\n",
    "    \n",
    "    return cell_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Rotate2D(points, centre, ang):\n",
    "    \n",
    "    ang = np.deg2rad(ang)\n",
    "    rotation_matrix = np.array([[np.cos(ang), np.sin(ang)], \n",
    "                                [-np.sin(ang), np.cos(ang)]])\n",
    "    return np.dot(points - centre, rotation_matrix) + centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_grid_latlong(df, lat_up, lat_down, long_up, long_down, cell_size):\n",
    "\n",
    "    df = df[['lat','long']].drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    lat = df['lat']\n",
    "    long = df['long']\n",
    "\n",
    "    dkx = haversine([lat_up, long_down], [lat_down, long_down]) \n",
    "    dky = haversine([lat_up, long_up], [lat_up, long_down])\n",
    "\n",
    "    Mx = np.ceil(1000 * dkx / (cell_size)) # check why 1000?\n",
    "    My = np.ceil(1000 * dky / (cell_size))\n",
    "\n",
    "    DX = (lat_up - lat_down) / Mx\n",
    "    DY = (long_up - long_down) / My\n",
    "\n",
    "    N = max(df.shape)\n",
    "\n",
    "    DX2 = DX * 2\n",
    "    DY2 = DY / 2\n",
    "\n",
    "    cell_polygons = []\n",
    "\n",
    "    for i in range(N):\n",
    "        \n",
    "        z2 = lat[i] - DX / 2\n",
    "        z1 = z2 + DX\n",
    "        z4 = long[i] - DY / 2\n",
    "        z3 = z4 + DY\n",
    "\n",
    "        V1 = np.asarray([z1, z2, z2, z1])\n",
    "        V2 = np.asarray([z3, z3, z4, z4])\n",
    "            \n",
    "        cell_polygons.append([V1.T, V2.T])\n",
    "\n",
    "        z2 = lat[i] - DX2 / 2\n",
    "        z1 = z2 + DX2\n",
    "        z4 = long[i] - DY2 / 2\n",
    "        z3 = z4 + DY2\n",
    "\n",
    "        V1 = np.asarray([z1, z2, z2, z1])\n",
    "        V2 = np.asarray([z3, z3, z4, z4])\n",
    "\n",
    "        #points = np.column_stack((V1, V2))\n",
    "        #centre = np.array([lat[i], long[i]])\n",
    "\n",
    "        points = [k for k in zip(V1, V2)]\n",
    "        points = np.asarray(points)\n",
    "        centre = [lat[i], long[i]]\n",
    "\n",
    "        angles = [45, 135, 0, 90]\n",
    "        for angle in angles:\n",
    "            poly_rot = Rotate2D(points, centre, angle)\n",
    "            v1 = np.asarray([k[0] for k in poly_rot])\n",
    "            v2 = np.asarray([k[1] for k in poly_rot])\n",
    "\n",
    "            cell_polygons.append([v1, v2])\n",
    "\n",
    "            #cell_polygons.append([poly_rot[:, 0], poly_rot[:, 1]])\n",
    "\n",
    "    return cell_polygons    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "def cell_crime_counts(df, cell_locations, start_date, end_date):\n",
    "    \n",
    "    polygons = [Polygon(np.column_stack(loc)) for loc in cell_locations]\n",
    "\n",
    "    df_filtered = df[(df['date'] >= start_date) & (df['date'] < end_date)]\n",
    "    lat_long_points = np.column_stack((df_filtered['lat'], df_filtered['long']))\n",
    "\n",
    "    cell_counts = np.array([sum([Point(point).within(poly) \n",
    "                            for point in lat_long_points]) \n",
    "                            for poly in polygons])\n",
    "    return cell_counts.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "def cell_crime_counts(df, cell_locations, start_date, end_date):\n",
    "\n",
    "    N = len(cell_locations)\n",
    "    cell_counts = np.zeros((N,1))\n",
    "    df = df[(df['date'] >= start_date) & (df['date'] < end_date)]\n",
    "\n",
    "    for i in range(N):\n",
    "        poly = np.asarray([k for k in zip(cell_locations[i][0], \n",
    "                                            cell_locations[i][1])])\n",
    "        poly = Polygon(poly)\n",
    "        cell_counts[i] = sum([Point(k).within(poly) \n",
    "                            for k in zip(df['lat'], df['long'])])\n",
    "    \n",
    "    return cell_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def daterange(start_date, end_date, interval):\n",
    "    \n",
    "    interval = timedelta(interval)\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        yield current_date\n",
    "        current_date += interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lat_max = data.lat.max()\n",
    "lat_min = data.lat.min()\n",
    "long_max = data.long.max()\n",
    "long_min = data.long.min()\n",
    "\n",
    "cell_size = 385.36\n",
    "\n",
    "train_start_date = pd.Timestamp(2021, 6, 30)\n",
    "train_end_date= pd.Timestamp(2022, 6, 30)\n",
    "test_start_date= pd.Timestamp(2022, 7, 1)\n",
    "test_end_date= pd.Timestamp(2022, 12, 31)\n",
    "\n",
    "cell_locations = setup_grid_latlong_train(lat_max, lat_min, long_max, \n",
    "                                        long_min, cell_size)\n",
    "\n",
    "cell_locations_test = setup_grid_latlong(data[data.date < test_start_date], \n",
    "                                        lat_max, lat_min, long_max, \n",
    "                                        long_min, cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for start_date in daterange(train_start_date, train_end_date, 30):\n",
    "    target = cell_crime_counts(data, cell_locations, \n",
    "                                start_date, start_date+timedelta(90))\n",
    "    Y_train.append(target)\n",
    "\n",
    "    print('Y_train {}'.format(start_date))\n",
    "\n",
    "    lst = []\n",
    "    time = [timedelta(7), timedelta(30), timedelta(90), \n",
    "            timedelta(365)]\n",
    "    for delta in time:\n",
    "        lst.append(cell_crime_counts(data, cell_locations, \n",
    "                                        start_date-delta, start_date))\n",
    "    X_train.append(lst)\n",
    "\n",
    "    print('X_train {}'.format(start_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for start_date in daterange(test_start_date, test_end_date, 15):\n",
    "    target = cell_crime_counts(data, cell_locations_test, \n",
    "                                start_date, start_date+timedelta(90))\n",
    "    Y_test.append(target)\n",
    "\n",
    "    print('Y_test {}'.format(start_date))\n",
    "\n",
    "    lst = []\n",
    "    time = [timedelta(7), timedelta(30), timedelta(90), \n",
    "            timedelta(365)]\n",
    "    for delta in time:\n",
    "        lst.append(cell_crime_counts(data, cell_locations_test, \n",
    "                                                start_date-delta, start_date))\n",
    "    X_test.append(lst)\n",
    "\n",
    "    print('X_test {}'.format(start_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('Y_train', 'wb') as fp:\n",
    "    pickle.dump(Y_train, fp)\n",
    "\n",
    "with open('X_train', 'wb') as fp:\n",
    "    pickle.dump(X_train, fp)\n",
    "\n",
    "with open('Y_test', 'wb') as fp:\n",
    "    pickle.dump(Y_test, fp)\n",
    "\n",
    "with open('X_test', 'wb') as fp:\n",
    "    pickle.dump(X_test, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
